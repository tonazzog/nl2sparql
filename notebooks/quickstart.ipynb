{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NL2SPARQL Quick Start Guide\n",
    "\n",
    "This notebook demonstrates all the main functionalities of the NL2SPARQL package for translating natural language questions into SPARQL queries for the LiITA knowledge base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "First, make sure you have the package installed:\n",
    "\n",
    "```bash\n",
    "pip install liita-nl2sparql[openai]  # or [anthropic], [mistral], [all]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key (uncomment and modify the one you need)\n",
    "import os\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\"\n",
    "# os.environ[\"ANTHROPIC_API_KEY\"] = \"your-anthropic-api-key\"\n",
    "# os.environ[\"MISTRAL_API_KEY\"] = \"your-mistral-api-key\"\n",
    "# os.environ[\"GEMINI_API_KEY\"] = \"your-gemini-api-key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Translation\n",
    "\n",
    "The simplest way to translate a natural language question to SPARQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nl2sparql import translate\n",
    "\n",
    "# Italian question\n",
    "result = translate(\"Quali lemmi esprimono tristezza?\")\n",
    "print(\"Generated SPARQL:\")\n",
    "print(result.sparql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English question\n",
    "result = translate(\"Find all nouns that express joy\")\n",
    "print(\"Generated SPARQL:\")\n",
    "print(result.sparql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Advanced Usage with NL2SPARQL Class\n",
    "\n",
    "For more control over the translation process, use the `NL2SPARQL` class directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nl2sparql import NL2SPARQL\n",
    "\n",
    "# Initialize with specific provider and options\n",
    "translator = NL2SPARQL(\n",
    "    provider=\"openai\",      # or \"anthropic\", \"mistral\", \"gemini\", \"ollama\"\n",
    "    model=\"gpt-4.1-mini\",   # optional: specify model\n",
    "    validate=True,          # validate generated queries\n",
    "    fix_errors=True,        # automatically fix invalid queries\n",
    "    max_retries=3           # retry attempts for fixing\n",
    ")\n",
    "\n",
    "print(\"Translator initialized successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate with full result details\n",
    "result = translator.translate(\"Trova le traduzioni siciliane di 'casa'\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TRANSLATION RESULT\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nDetected patterns: {result.detected_patterns}\")\n",
    "print(f\"Confidence: {result.confidence:.2f}\")\n",
    "print(f\"\\nValidation:\")\n",
    "print(f\"  - Syntax valid: {result.validation.syntax_valid}\")\n",
    "print(f\"  - Execution success: {result.validation.execution_success}\")\n",
    "print(f\"  - Result count: {result.validation.result_count}\")\n",
    "print(f\"\\nGenerated SPARQL:\")\n",
    "print(result.sparql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if query was auto-fixed\n",
    "if result.was_fixed:\n",
    "    print(f\"Query was fixed after {result.fix_attempts} attempt(s)\")\n",
    "else:\n",
    "    print(\"Query was valid on first attempt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Agentic Translation with LangGraph\n",
    "\n",
    "The agent module provides an advanced agentic workflow using LangGraph. It features:\n",
    "- Iterative refinement with automatic error correction\n",
    "- Schema exploration when queries return empty results\n",
    "- Semantic verification of results\n",
    "\n",
    "**Installation:**\n",
    "```bash\n",
    "pip install liita-nl2sparql[agent-openai]  # or [agent-anthropic], [agent-mistral]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nl2sparql.agent import NL2SPARQLAgent\n",
    "\n",
    "# Initialize the agent\n",
    "agent = NL2SPARQLAgent(\n",
    "    provider=\"openai\",      # or \"anthropic\", \"mistral\", \"gemini\", \"ollama\"\n",
    "    model=\"gpt-4.1-mini\",   # optional: uses provider default if None\n",
    ")\n",
    "\n",
    "print(\"Agent initialized successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic agent translation\n",
    "result = agent.translate(\"Quali lemmi esprimono tristezza?\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"AGENT TRANSLATION RESULT\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nDetected patterns: {result['detected_patterns']}\")\n",
    "print(f\"Confidence: {result['confidence']:.2f}\")\n",
    "print(f\"Attempts: {result['attempts']}\")\n",
    "print(f\"Valid: {result['is_valid']}\")\n",
    "print(f\"Result count: {result['result_count']}\")\n",
    "print(f\"\\nGenerated SPARQL:\")\n",
    "print(result[\"sparql\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streaming mode - watch the agent work step by step\n",
    "print(\"Streaming agent workflow:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "final_state = None\n",
    "for node_name, state in agent.stream(\"Trova le traduzioni siciliane di 'casa'\"):\n",
    "    final_state = state\n",
    "    \n",
    "    if node_name == \"analyze\":\n",
    "        print(f\"[analyze] Patterns: {state.get('detected_patterns')}, Complexity: {state.get('complexity')}\")\n",
    "    elif node_name == \"plan\":\n",
    "        print(f\"[plan] Sub-tasks: {len(state.get('sub_tasks', []))}\")\n",
    "    elif node_name == \"retrieve\":\n",
    "        print(f\"[retrieve] Examples: {len(state.get('retrieved_examples', []))}\")\n",
    "    elif node_name == \"generate\":\n",
    "        print(f\"[generate] Attempt: {state.get('generation_attempts')}\")\n",
    "    elif node_name == \"execute\":\n",
    "        error = state.get('execution_error')\n",
    "        if error:\n",
    "            print(f\"[execute] Error: {error}\")\n",
    "        else:\n",
    "            print(f\"[execute] Results: {state.get('result_count')}\")\n",
    "    elif node_name == \"verify\":\n",
    "        if state.get('is_valid'):\n",
    "            print(f\"[verify] Valid!\")\n",
    "        else:\n",
    "            print(f\"[verify] Issues: {state.get('validation_errors')}\")\n",
    "    elif node_name == \"refine\":\n",
    "        print(f\"[refine] Retrying...\")\n",
    "    elif node_name == \"output\":\n",
    "        print(f\"[output] Done!\")\n",
    "\n",
    "# Get final result from accumulated state\n",
    "result = agent.get_final_result(final_state)\n",
    "print(f\"\\nFinal SPARQL ({result['attempts']} attempt(s), {result['result_count']} results):\")\n",
    "print(result[\"sparql\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verbose mode - built-in progress output\n",
    "result = agent.translate(\n",
    "    \"Qual è la definizione di 'amore'?\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal SPARQL:\\n{result['sparql']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check refinement history (if the agent had to retry)\n",
    "result = agent.translate(\"Trova tutti gli iponimi di 'animale'\")\n",
    "\n",
    "if result[\"refinement_history\"]:\n",
    "    print(f\"Agent refined the query {len(result['refinement_history'])} time(s):\")\n",
    "    for i, attempt in enumerate(result[\"refinement_history\"], 1):\n",
    "        print(f\"\\n  Attempt {i}:\")\n",
    "        print(f\"    Error: {attempt['error'][:100]}...\")\n",
    "        print(f\"    Results: {attempt['result_count']}\")\n",
    "else:\n",
    "    print(\"Query was valid on first attempt!\")\n",
    "\n",
    "print(f\"\\nFinal result:\")\n",
    "print(f\"  Valid: {result['is_valid']}\")\n",
    "print(f\"  Confidence: {result['confidence']:.2f}\")\n",
    "print(f\"  Results: {result['result_count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Async usage (for async contexts)\n",
    "import asyncio\n",
    "\n",
    "async def translate_async():\n",
    "    result = await agent.atranslate(\"Lemmi che esprimono rabbia\")\n",
    "    return result\n",
    "\n",
    "# Run in Jupyter (already has event loop)\n",
    "result = await translate_async()\n",
    "print(f\"Async result: {result['is_valid']}, {result['result_count']} results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Working with Retrieved Examples\n",
    "\n",
    "See which examples were retrieved for few-shot learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = translator.translate(\"Quali sono gli iperonimi di 'cane'?\")\n",
    "\n",
    "print(\"Retrieved examples for few-shot learning:\")\n",
    "print(\"=\" * 60)\n",
    "for i, ex in enumerate(result.retrieved_examples[:3], 1):\n",
    "    print(f\"\\n{i}. Score: {ex.score:.3f}\")\n",
    "    print(f\"   Question: {ex.example.nl}\")\n",
    "    print(f\"   SPARQL preview: {ex.example.sparql[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Query Types Examples\n",
    "\n",
    "Examples of different query types supported by the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to display results\n",
    "def show_translation(question: str, language: str = \"it\"):\n",
    "    \"\"\"Translate and display results.\"\"\"\n",
    "    print(f\"\\nQuestion ({language}): {question}\")\n",
    "    print(\"-\" * 60)\n",
    "    result = translator.translate(question)\n",
    "    print(f\"Patterns: {result.detected_patterns}\")\n",
    "    print(f\"Valid: {result.validation.syntax_valid}, Results: {result.validation.result_count}\")\n",
    "    print(f\"\\nSPARQL:\\n{result.sparql}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion query (ELITA)\n",
    "_ = show_translation(\"Quali lemmi esprimono paura?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation query (Sicilian)\n",
    "_ = show_translation(\"Traduzioni siciliane di 'acqua'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition query (CompL-it)\n",
    "_ = show_translation(\"Qual è la definizione di 'amore'?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic relations (hypernyms)\n",
    "_ = show_translation(\"What are the hypernyms of 'dog'?\", \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part of speech filter\n",
    "_ = show_translation(\"Find all verbs in LiITA\", \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Morphological pattern\n",
    "_ = show_translation(\"Lemmi che iniziano con 'pre'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Single Model Evaluation\n",
    "\n",
    "Run systematic evaluation on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nl2sparql.evaluation import (\n",
    "    evaluate_dataset,\n",
    "    evaluate_single,\n",
    "    load_test_dataset,\n",
    "    print_report,\n",
    "    save_report,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and inspect the test dataset\n",
    "test_data = load_test_dataset()\n",
    "\n",
    "print(f\"Dataset version: {test_data['metadata']['version']}\")\n",
    "print(f\"Total test cases: {len(test_data['test_cases'])}\")\n",
    "print(f\"Patterns covered: {test_data['metadata']['patterns_covered']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate a single test case\n",
    "test_case = test_data[\"test_cases\"][0]\n",
    "print(f\"Test case: {test_case['id']}\")\n",
    "print(f\"Question (IT): {test_case['nl_it']}\")\n",
    "print(f\"Question (EN): {test_case['nl_en']}\")\n",
    "print(f\"Expected patterns: {test_case['patterns']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run single test\n",
    "result = evaluate_single(test_case, translator, language=\"it\")\n",
    "\n",
    "print(f\"\\nResults for {result.test_id}:\")\n",
    "print(f\"  Syntax valid: {result.syntax_valid}\")\n",
    "print(f\"  Endpoint valid: {result.endpoint_valid}\")\n",
    "print(f\"  Component score: {result.component_score:.2%}\")\n",
    "print(f\"  Generation time: {result.generation_time:.2f}s\")\n",
    "if result.missing_components:\n",
    "    print(f\"  Missing components: {result.missing_components}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation on a subset (single_pattern category only, for speed)\n",
    "report = evaluate_dataset(\n",
    "    translator,\n",
    "    language=\"it\",\n",
    "    categories=[\"single_pattern\"],  # Filter to single pattern tests\n",
    "    validate_endpoint=True,\n",
    ")\n",
    "\n",
    "print_report(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save report with generated SPARQL queries\n",
    "save_report(report, \"evaluation_report.json\")\n",
    "print(\"Report saved to evaluation_report.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect a generated query from the report\n",
    "import json\n",
    "\n",
    "with open(\"evaluation_report.json\", \"r\") as f:\n",
    "    saved_report = json.load(f)\n",
    "\n",
    "# Show first test result with its generated SPARQL\n",
    "first_result = saved_report[\"test_results\"][0]\n",
    "print(f\"Test: {first_result['test_id']}\")\n",
    "print(f\"Question: {first_result['question']}\")\n",
    "print(f\"\\nGenerated SPARQL:\")\n",
    "print(first_result[\"generated_sparql\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Batch Model Comparison\n",
    "\n",
    "Compare multiple LLM providers and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nl2sparql.evaluation import (\n",
    "    ModelConfig,\n",
    "    run_batch_evaluation,\n",
    "    create_comparison_report,\n",
    "    print_comparison,\n",
    "    PRESETS,\n",
    ")\n",
    "\n",
    "# View available presets\n",
    "print(\"Available presets:\")\n",
    "for name, configs in PRESETS.items():\n",
    "    models = [c.name for c in configs]\n",
    "    print(f\"  {name}: {models}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom model configurations\n",
    "custom_configs = [\n",
    "    ModelConfig(\"openai\", \"gpt-4.1-mini\", \"GPT-4.1-mini\"),\n",
    "    # Add more as needed:\n",
    "    # ModelConfig(\"anthropic\", \"claude-3-5-haiku-20241022\", \"Claude 3.5 Haiku\"),\n",
    "    # ModelConfig(\"mistral\", \"mistral-small-latest\", \"Mistral Small\"),\n",
    "]\n",
    "\n",
    "print(f\"Testing {len(custom_configs)} model(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run batch evaluation (on single_pattern only for speed)\n",
    "# Note: This will take some time depending on the number of models and tests\n",
    "\n",
    "results = run_batch_evaluation(\n",
    "    configs=custom_configs,\n",
    "    language=\"it\",\n",
    "    validate_endpoint=True,\n",
    "    categories=[\"single_pattern\"],  # Subset for demo\n",
    "    output_dir=\"./batch_reports\",   # Save individual reports\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and display comparison\n",
    "comparison = create_comparison_report(results, \"model_comparison.json\")\n",
    "print_comparison(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access comparison data programmatically\n",
    "print(\"\\nProgrammatic access to comparison data:\")\n",
    "for model in comparison[\"models\"]:\n",
    "    if model.get(\"syntax_valid_rate\") is not None:\n",
    "        print(f\"\\n{model['name']}:\")\n",
    "        print(f\"  Syntax validity: {model['syntax_valid_rate']:.1%}\")\n",
    "        print(f\"  Endpoint success: {model['endpoint_valid_rate']:.1%}\")\n",
    "        print(f\"  Component score: {model['avg_component_score']:.1%}\")\n",
    "        print(f\"  Avg time: {model['avg_generation_time']:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Testing Generated Queries\n",
    "\n",
    "You can copy generated queries and test them directly on the LiITA SPARQL endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from nl2sparql.config import LIITA_ENDPOINT\n",
    "\n",
    "def execute_sparql(query: str, limit: int = 10):\n",
    "    \"\"\"Execute a SPARQL query on the LiITA endpoint.\"\"\"\n",
    "    sparql = SPARQLWrapper(LIITA_ENDPOINT)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    sparql.addCustomHttpHeader(\"Accept\", \"application/sparql-results+json\")\n",
    "    \n",
    "    try:\n",
    "        results = sparql.query().convert()\n",
    "        bindings = results[\"results\"][\"bindings\"]\n",
    "        print(f\"Endpoint: {LIITA_ENDPOINT}\")\n",
    "        print(f\"Found {len(bindings)} results\")\n",
    "        \n",
    "        if bindings:\n",
    "            # Get column names\n",
    "            cols = list(bindings[0].keys())\n",
    "            print(f\"Columns: {cols}\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            # Display first N results\n",
    "            for row in bindings[:limit]:\n",
    "                values = [row[c][\"value\"][:50] for c in cols]\n",
    "                print(\" | \".join(values))\n",
    "                \n",
    "        return bindings\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and execute a query\n",
    "result = translator.translate(\"Lemmi che esprimono gioia\")\n",
    "print(\"Query:\")\n",
    "print(result.sparql)\n",
    "print(\"\\nResults:\")\n",
    "_ = execute_sparql(result.sparql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Clean up generated files\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "files_to_remove = [\"evaluation_report.json\", \"model_comparison.json\"]\n",
    "dirs_to_remove = [\"batch_reports\"]\n",
    "\n",
    "for f in files_to_remove:\n",
    "    if os.path.exists(f):\n",
    "        os.remove(f)\n",
    "        print(f\"Removed {f}\")\n",
    "\n",
    "for d in dirs_to_remove:\n",
    "    if os.path.exists(d):\n",
    "        shutil.rmtree(d)\n",
    "        print(f\"Removed {d}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Basic translation** using the `translate()` function\n",
    "2. **Advanced usage** with the `NL2SPARQL` class for more control\n",
    "3. **Agentic translation** with `NL2SPARQLAgent` featuring iterative refinement, streaming, and semantic verification\n",
    "4. **Retrieved examples** inspection for few-shot learning\n",
    "5. **Different query types**: emotions, translations, definitions, semantic relations, POS filters, morphological patterns\n",
    "6. **Single model evaluation** with metrics and reports\n",
    "7. **Batch model comparison** across multiple LLM providers\n",
    "8. **Direct query execution** on the LiITA SPARQL endpoint\n",
    "\n",
    "For more information, see:\n",
    "- [README.md](../README.md)\n",
    "- [Evaluation Documentation](../docs/evaluation.md)\n",
    "- [Architecture Documentation](../docs/architecture.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
